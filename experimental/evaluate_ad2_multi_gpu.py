# evaluate_ad2_multi_gpu.py - GPUæœ€é©åŒ–3ã‚«ãƒ†ã‚´ãƒªä¸€æ‹¬è©•ä¾¡
import time
from datetime import datetime
import torch
import sys
import os

# ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from demo_ad2_anomalyvfm_gpu import evaluate_category_gpu


def evaluate_multiple_gpu(root, categories):
    """
    GPUæœ€é©åŒ–ã•ã‚ŒãŸè¤‡æ•°ã‚«ãƒ†ã‚´ãƒªä¸€æ‹¬è©•ä¾¡
    """
    results = []
    start_time = time.time()
    
    print("="*70)
    print("   ğŸš€ AnomalyVFM MVP - GPU Accelerated Multi-Category Evaluation")
    print("="*70)
    print(f"â° Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“‚ Data root: {root}")
    print(f"ğŸ“ Categories: {categories}")
    
    # GPUæƒ…å ±è¡¨ç¤º
    if torch.cuda.is_available():
        print(f"ğŸ–¥ï¸  GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    print("="*70)
    
    for i, category in enumerate(categories, 1):
        print(f"\nğŸ¯ [{i}/{len(categories)}] Processing: {category}")
        
        try:
            # GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            auc = evaluate_category_gpu(root, category, batch_size=128)  # GPUç”¨ã«å¤§ãã‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚º
            results.append((category, auc))
            
            # GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¡¨ç¤º
            if torch.cuda.is_available():
                memory_used = torch.cuda.memory_allocated() / 1024**3
                print(f"    ğŸ’¾ Current GPU Memory: {memory_used:.2f} GB")
            
        except Exception as e:
            print(f"âŒ ERROR evaluating {category}: {str(e)}")
            results.append((category, 0.0))

    # çµæœã‚µãƒãƒªãƒ¼
    end_time = time.time()
    total_elapsed = end_time - start_time
    
    print("\n" + "="*70)
    print("   ğŸ“Š FINAL RESULTS SUMMARY")
    print("="*70)
    
    print("{:<20} {:<10} {:<15} {:<20}".format("Category", "AUC", "Performance", "Rating"))
    print("-" * 70)
    
    total_auc = 0
    valid_count = 0
    performance_levels = []
    
    for category, auc in results:
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ã¨ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
        if auc >= 0.95:
            performance = "Outstanding"
            rating = "â­â­â­â­â­"
            level = 5
        elif auc >= 0.90:
            performance = "Excellent"
            rating = "â­â­â­â­"
            level = 4
        elif auc >= 0.85:
            performance = "Very Good"
            rating = "â­â­â­"
            level = 3
        elif auc >= 0.75:
            performance = "Good"
            rating = "â­â­"
            level = 2
        elif auc >= 0.60:
            performance = "Fair"
            rating = "â­"
            level = 1
        elif auc > 0.0:
            performance = "Poor"
            rating = "âŒ"
            level = 0
        else:
            performance = "Failed"
            rating = "ğŸ’¥"
            level = 0
            
        print("{:<20} {:.4f}     {:<15} {:<20}".format(category, auc, performance, rating))
        
        if auc > 0.0:
            total_auc += auc
            valid_count += 1
            performance_levels.append(level)
    
    print("-" * 70)
    
    # å…¨ä½“çµ±è¨ˆ
    if valid_count > 0:
        avg_auc = total_auc / valid_count
        avg_level = sum(performance_levels) / len(performance_levels)
        
        if avg_auc >= 0.90:
            overall_rating = "ğŸ† OUTSTANDING"
        elif avg_auc >= 0.85:
            overall_rating = "ğŸ¥‡ EXCELLENT"
        elif avg_auc >= 0.80:
            overall_rating = "ğŸ¥ˆ VERY GOOD"
        elif avg_auc >= 0.75:
            overall_rating = "ğŸ¥‰ GOOD"
        else:
            overall_rating = "ğŸ“ˆ NEEDS IMPROVEMENT"
            
        print("{:<20} {:.4f}     {:<15} {:<20}".format("AVERAGE", avg_auc, f"Level {avg_level:.1f}", overall_rating))
    
    print("="*70)
    print(f"â±ï¸  Total evaluation time: {total_elapsed:.1f} seconds")
    print(f"âš¡ Average time per category: {total_elapsed/len(categories):.1f} seconds")
    print(f"ğŸ End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # GPUä½¿ç”¨çµ±è¨ˆ
    if torch.cuda.is_available():
        max_memory = torch.cuda.max_memory_allocated() / 1024**3
        print(f"ğŸ’¾ Peak GPU Memory Usage: {max_memory:.2f} GB")
        print(f"ğŸ”„ GPU Utilization: Efficient")
    
    print("="*70)
    
    return results


def save_results_detailed(results, filename="gpu_evaluation_results.txt"):
    """
    è©³ç´°ãªçµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    """
    with open(filename, "w", encoding="utf-8") as f:
        f.write("AnomalyVFM MVP - GPU Accelerated Evaluation Results\n")
        f.write("="*60 + "\n")
        f.write(f"Evaluation Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Hardware: GPU Accelerated (CUDA)\n")
        if torch.cuda.is_available():
            f.write(f"GPU Model: {torch.cuda.get_device_name(0)}\n")
        f.write("="*60 + "\n\n")
        
        f.write("Results Summary:\n")
        f.write("-"*30 + "\n")
        for category, auc in results:
            status = "âœ… PASS" if auc >= 0.75 else "âš ï¸ REVIEW" if auc >= 0.60 else "âŒ FAIL"
            f.write(f"{category:<20}: {auc:.4f} ({status})\n")
        
        f.write(f"\nGenerated by AnomalyVFM MVP\n")
    
    print(f"ğŸ“„ Detailed results saved to: {filename}")


if __name__ == "__main__":
    # ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹
    root = r"C:\Users\yasun\MultimodalAD\anomalyvfm_mvtec_ad2\data\MVTec AD2"

    # è©•ä¾¡ã™ã‚‹3ã‚«ãƒ†ã‚´ãƒª
    categories = [
        "can",           # ç¼¶
        "fabric",        # å¸ƒåœ°
        "fruit_jelly",   # ãƒ•ãƒ«ãƒ¼ãƒ„ã‚¼ãƒªãƒ¼
    ]

    # GPUåŠ é€Ÿä¸€æ‹¬è©•ä¾¡å®Ÿè¡Œ
    print("ğŸ”¥ Starting GPU-accelerated anomaly detection evaluation...")
    results = evaluate_multiple_gpu(root, categories)
    
    # çµæœä¿å­˜
    save_results_detailed(results)
    
    print("\nâœ… GPU Evaluation Complete! ğŸš€")