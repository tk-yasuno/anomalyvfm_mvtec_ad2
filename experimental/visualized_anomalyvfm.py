# visualized_anomalyvfm.py - å¯è¦–åŒ–æ©Ÿèƒ½ä»˜ãAnomalyVFM
import torch
import timm
import numpy as np
from torch.utils.data import DataLoader
from sklearn.covariance import EmpiricalCovariance
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.preprocessing import StandardScaler
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import warnings
import time
import os
from datetime import datetime

from dataset_ad2 import AD2TrainDataset, AD2TestDataset

warnings.filterwarnings('ignore')

# ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸš€ AnomalyVFM Visualized - Using device: {device}")

if torch.cuda.is_available():
    print(f"ğŸ–¥ï¸  GPU: {torch.cuda.get_device_name(0)}")


class AnomalyVFMVisualizer:
    """
    AnomalyVFMã®å¯è¦–åŒ–ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, save_dir="visualizations"):
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)
        
    def plot_roc_curve(self, y_true, y_scores, category, save_name=None):
        """
        ROCæ›²ç·šã¨AUCã‚’å¯è¦–åŒ–
        """
        fpr, tpr, thresholds = roc_curve(y_true, y_scores)
        auc = roc_auc_score(y_true, y_scores)
        
        plt.figure(figsize=(10, 8))
        
        # ROCæ›²ç·š
        plt.plot(fpr, tpr, color='darkorange', lw=3, 
                label=f'ROC curve (AUC = {auc:.4f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', 
                label='Random classifier')
        
        # æœ€é©é–¾å€¤ã®ç‚¹ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        optimal_idx = np.argmax(tpr - fpr)
        optimal_threshold = thresholds[optimal_idx]
        plt.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', markersize=10,
                label=f'Optimal threshold = {optimal_threshold:.3f}')
        
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate', fontsize=14)
        plt.ylabel('True Positive Rate', fontsize=14)
        plt.title(f'ROC Curve - {category.upper()}', fontsize=16, fontweight='bold')
        plt.legend(loc="lower right", fontsize=12)
        plt.grid(True, alpha=0.3)
        
        # AUCã‚¹ã‚³ã‚¢ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§è¿½åŠ 
        plt.text(0.6, 0.2, f'AUC = {auc:.4f}', 
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"),
                fontsize=14, fontweight='bold')
        
        if save_name:
            plt.savefig(os.path.join(self.save_dir, f"{save_name}_roc.png"), 
                       dpi=300, bbox_inches='tight')
        plt.show()
        
        return auc, optimal_threshold
    
    def plot_anomaly_scores_distribution(self, scores, labels, category, save_name=None):
        """
        ç•°å¸¸ã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒã‚’ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã§å¯è¦–åŒ–
        """
        normal_scores = scores[labels == 0]
        anomaly_scores = scores[labels == 1]
        
        plt.figure(figsize=(12, 6))
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        plt.hist(normal_scores, bins=50, alpha=0.7, color='blue', 
                label=f'Normal (n={len(normal_scores)})', density=True)
        plt.hist(anomaly_scores, bins=50, alpha=0.7, color='red', 
                label=f'Anomaly (n={len(anomaly_scores)})', density=True)
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
        normal_mean, normal_std = np.mean(normal_scores), np.std(normal_scores)
        anomaly_mean, anomaly_std = np.mean(anomaly_scores), np.std(anomaly_scores)
        
        plt.axvline(normal_mean, color='blue', linestyle='--', alpha=0.8,
                   label=f'Normal mean = {normal_mean:.3f}')
        plt.axvline(anomaly_mean, color='red', linestyle='--', alpha=0.8,
                   label=f'Anomaly mean = {anomaly_mean:.3f}')
        
        plt.xlabel('Anomaly Score', fontsize=14)
        plt.ylabel('Density', fontsize=14)
        plt.title(f'Anomaly Score Distribution - {category.upper()}', 
                 fontsize=16, fontweight='bold')
        plt.legend(fontsize=12)
        plt.grid(True, alpha=0.3)
        
        if save_name:
            plt.savefig(os.path.join(self.save_dir, f"{save_name}_scores.png"), 
                       dpi=300, bbox_inches='tight')
        plt.show()
        
        return {
            'normal_mean': normal_mean, 'normal_std': normal_std,
            'anomaly_mean': anomaly_mean, 'anomaly_std': anomaly_std,
            'separation_ratio': (anomaly_mean - normal_mean) / (normal_std + anomaly_std)
        }
    
    def plot_features_heatmap(self, features, labels, category, max_features=50, save_name=None):
        """
        ç‰¹å¾´é‡ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–
        """
        # ç‰¹å¾´é‡æ•°ã‚’åˆ¶é™ï¼ˆè¨ˆç®—åŠ¹ç‡ã®ãŸã‚ï¼‰
        n_features = min(max_features, features.shape[1])
        selected_features = features[:, :n_features]
        
        # æ­£å¸¸ãƒ»ç•°å¸¸åˆ¥ã®å¹³å‡ç‰¹å¾´é‡
        normal_features = selected_features[labels == 0]
        anomaly_features = selected_features[labels == 1]
        
        normal_mean = np.mean(normal_features, axis=0)
        anomaly_mean = np.mean(anomaly_features, axis=0)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        heatmap_data = pd.DataFrame({
            'Normal': normal_mean,
            'Anomaly': anomaly_mean,
            'Difference': anomaly_mean - normal_mean
        }, index=[f'Feature_{i:03d}' for i in range(n_features)])
        
        plt.figure(figsize=(12, 8))
        sns.heatmap(heatmap_data.T, cmap='RdBu_r', center=0, 
                   cbar_kws={'label': 'Feature Value'})
        plt.title(f'Feature Heatmap - {category.upper()}', 
                 fontsize=16, fontweight='bold')
        plt.xlabel('Features', fontsize=14)
        plt.ylabel('Sample Type', fontsize=14)
        
        if save_name:
            plt.savefig(os.path.join(self.save_dir, f"{save_name}_heatmap.png"), 
                       dpi=300, bbox_inches='tight')
        plt.show()
        
    def plot_tsne_features(self, features, labels, category, save_name=None):
        """
        t-SNEã‚’ä½¿ç”¨ã—ãŸç‰¹å¾´é‡ã®2Då¯è¦–åŒ–
        """
        print(f"  ğŸ”„ Computing t-SNE for {category}...")
        
        # ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’åˆ¶é™ï¼ˆt-SNEã¯è¨ˆç®—ãŒé‡ã„ãŸã‚ï¼‰
        max_samples = min(1000, len(features))
        indices = np.random.choice(len(features), max_samples, replace=False)
        
        features_subset = features[indices]
        labels_subset = labels[indices]
        
        # t-SNEå®Ÿè¡Œ
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        features_2d = tsne.fit_transform(features_subset)
        
        plt.figure(figsize=(10, 8))
        
        # æ­£å¸¸ãƒ»ç•°å¸¸ã‚’è‰²åˆ†ã‘ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆ
        normal_mask = labels_subset == 0
        anomaly_mask = labels_subset == 1
        
        plt.scatter(features_2d[normal_mask, 0], features_2d[normal_mask, 1], 
                   c='blue', alpha=0.6, s=50, label=f'Normal (n={np.sum(normal_mask)})')
        plt.scatter(features_2d[anomaly_mask, 0], features_2d[anomaly_mask, 1], 
                   c='red', alpha=0.6, s=50, label=f'Anomaly (n={np.sum(anomaly_mask)})')
        
        plt.xlabel('t-SNE Component 1', fontsize=14)
        plt.ylabel('t-SNE Component 2', fontsize=14)
        plt.title(f't-SNE Feature Visualization - {category.upper()}', 
                 fontsize=16, fontweight='bold')
        plt.legend(fontsize=12)
        plt.grid(True, alpha=0.3)
        
        if save_name:
            plt.savefig(os.path.join(self.save_dir, f"{save_name}_tsne.png"), 
                       dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_summary_report(self, results_dict, save_name="summary_report"):
        """
        çµæœã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ
        """
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        categories = list(results_dict.keys())
        aucs = [results_dict[cat]['auc'] for cat in categories]
        
        # 1. AUCãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        bars = ax1.bar(categories, aucs, color=['red' if auc < 0.6 else 'orange' if auc < 0.8 else 'green' for auc in aucs])
        ax1.set_ylabel('AUC Score', fontsize=12)
        ax1.set_title('AUC Scores by Category', fontsize=14, fontweight='bold')
        ax1.set_ylim(0, 1)
        ax1.grid(True, alpha=0.3)
        
        # ãƒãƒ¼ã«å€¤ã‚’è¡¨ç¤º
        for bar, auc in zip(bars, aucs):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{auc:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 2. å‡¦ç†æ™‚é–“
        times = [results_dict[cat]['time'] for cat in categories]
        ax2.bar(categories, times, color='skyblue')
        ax2.set_ylabel('Time (seconds)', fontsize=12)
        ax2.set_title('Processing Time by Category', fontsize=14, fontweight='bold')
        ax2.grid(True, alpha=0.3)
        
        # 3. ç•°å¸¸åˆ†é›¢åº¦ï¼ˆNormal-Anomalyåˆ†é›¢ã®è‰¯ã•ï¼‰
        separations = [results_dict[cat]['separation_ratio'] for cat in categories]
        ax3.bar(categories, separations, color='lightcoral')
        ax3.set_ylabel('Separation Ratio', fontsize=12)
        ax3.set_title('Normal-Anomaly Separation', fontsize=14, fontweight='bold')
        ax3.grid(True, alpha=0.3)
        
        # 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†é¡
        performance_counts = {'Excellent': 0, 'Good': 0, 'Fair': 0, 'Poor': 0}
        for auc in aucs:
            if auc >= 0.9: performance_counts['Excellent'] += 1
            elif auc >= 0.7: performance_counts['Good'] += 1
            elif auc >= 0.6: performance_counts['Fair'] += 1
            else: performance_counts['Poor'] += 1
        
        ax4.pie(performance_counts.values(), labels=performance_counts.keys(), 
               autopct='%1.0f%%', colors=['green', 'blue', 'orange', 'red'])
        ax4.set_title('Performance Distribution', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        
        if save_name:
            plt.savefig(os.path.join(self.save_dir, f"{save_name}.png"), 
                       dpi=300, bbox_inches='tight')
        plt.show()


def evaluate_category_with_visualization(root, category, visualizer, batch_size=32):
    """
    å¯è¦–åŒ–ä»˜ãã‚«ãƒ†ã‚´ãƒªè©•ä¾¡
    """
    print(f"\n{'='*60}")
    print(f"  ğŸ¯ AnomalyVFM Visualization: {category.upper()}")
    print(f"{'='*60}")
    
    start_time = time.time()
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (DINOv2ç”¨: 518x518)
        train_ds = AD2TrainDataset(root, category, image_size=518)
        test_ds = AD2TestDataset(root, category, image_size=518)
        
        print(f"  ğŸ“Š Data: {len(train_ds)} train, {len(test_ds)} test")
        
        if len(train_ds) == 0 or len(test_ds) == 0:
            print("  âŒ No data available")
            return None
        
        # DataLoader
        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, 
                                 num_workers=2, pin_memory=True if device=='cuda' else False)
        test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, 
                                num_workers=2, pin_memory=True if device=='cuda' else False)
        
        # ãƒ¢ãƒ‡ãƒ«
        print("  ğŸ¤– Loading DINOv2-ViT-Base...")
        model = timm.create_model("vit_base_patch14_dinov2", pretrained=True, num_classes=0)
        model = model.to(device).eval()
        
        # ç‰¹å¾´é‡æŠ½å‡ºï¼ˆè¨“ç·´ï¼‰
        print("  ğŸ“ˆ Extracting training features...")
        train_features = []
        with torch.no_grad():
            for batch_idx, images in enumerate(train_loader):
                images = images.to(device, non_blocking=True)
                feats = model(images)
                train_features.append(feats.cpu())
        
        train_features = torch.cat(train_features, dim=0).numpy()
        
        # ç‰¹å¾´é‡æŠ½å‡ºï¼ˆãƒ†ã‚¹ãƒˆï¼‰
        print("  ğŸ” Extracting test features...")
        test_features = []
        test_labels = []
        
        with torch.no_grad():
            for batch_idx, (images, labels) in enumerate(test_loader):
                images = images.to(device, non_blocking=True)
                feats = model(images)
                test_features.append(feats.cpu())
                test_labels.extend(labels.numpy())
        
        test_features = torch.cat(test_features, dim=0).numpy()
        test_labels = np.array(test_labels)
        
        # ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—
        print("  âš¡ Computing anomaly scores...")
        scaler = StandardScaler()
        train_scaled = scaler.fit_transform(train_features)
        test_scaled = scaler.transform(test_features)
        
        try:
            cov = EmpiricalCovariance().fit(train_scaled)
            mean = cov.location_
            precision = cov.precision_
            
            scores = []
            for sample in test_scaled:
                diff = sample - mean
                score = float(diff @ precision @ diff.T)
                scores.append(score)
            scores = np.array(scores)
            
        except:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            mean_train = np.mean(train_scaled, axis=0)
            scores = np.linalg.norm(test_scaled - mean_train, axis=1)
        
        # å¯è¦–åŒ–å®Ÿè¡Œ
        print("  ğŸ¨ Creating visualizations...")
        save_name = f"{category}_{datetime.now().strftime('%m%d_%H%M')}"
        
        # 1. ROCæ›²ç·š
        auc, optimal_threshold = visualizer.plot_roc_curve(
            test_labels, scores, category, save_name)
        
        # 2. ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
        score_stats = visualizer.plot_anomaly_scores_distribution(
            scores, test_labels, category, save_name)
        
        # 3. ç‰¹å¾´é‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        visualizer.plot_features_heatmap(
            test_features, test_labels, category, save_name=save_name)
        
        # 4. t-SNEå¯è¦–åŒ–
        visualizer.plot_tsne_features(
            test_features, test_labels, category, save_name)
        
        elapsed_time = time.time() - start_time
        
        # çµæœ
        print(f"\n  ğŸ“Š Results:")
        print(f"    AUC Score: {auc:.4f}")
        print(f"    Optimal Threshold: {optimal_threshold:.4f}")
        print(f"    Separation Ratio: {score_stats['separation_ratio']:.3f}")
        print(f"    Processing Time: {elapsed_time:.1f}s")
        
        return {
            'category': category,
            'auc': auc,
            'optimal_threshold': optimal_threshold,
            'separation_ratio': score_stats['separation_ratio'],
            'time': elapsed_time,
            'normal_mean': score_stats['normal_mean'],
            'anomaly_mean': score_stats['anomaly_mean']
        }
        
    except Exception as e:
        print(f"  âŒ Error: {str(e)}")
        return None
    
    finally:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()


def run_visualization_demo():
    """
    å¯è¦–åŒ–ãƒ‡ãƒ¢å®Ÿè¡Œ
    """
    root = r"C:\Users\yasun\MultimodalAD\anomalyvfm_mvtec_ad2\data\MVTec AD2"
    
    # ãƒ‡ãƒ¢ç”¨ã«3ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠï¼ˆæ™‚é–“ç¯€ç´„ï¼‰
    demo_categories = ["fruit_jelly", "fabric", "can"]  # é«˜æ€§èƒ½ã‚«ãƒ†ã‚´ãƒªã‚’å…ˆã«
    
    print("ğŸ¨" * 60)
    print("   AnomalyVFM - Advanced Visualization Demo")
    print("ğŸ¨" * 60)
    print(f"â° Start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“‚ Categories: {demo_categories}")
    
    # å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«åˆæœŸåŒ–
    visualizer = AnomalyVFMVisualizer(save_dir="anomaly_visualizations")
    
    results = {}
    total_start = time.time()
    
    # å„ã‚«ãƒ†ã‚´ãƒªã®å‡¦ç†
    for i, category in enumerate(demo_categories, 1):
        print(f"\nğŸ¯ [{i}/{len(demo_categories)}] Processing: {category}")
        result = evaluate_category_with_visualization(root, category, visualizer)
        
        if result:
            results[category] = result
            
            # ä¸­é–“çµæœè¡¨ç¤º
            grade = "ğŸ† EXCELLENT" if result['auc'] >= 0.9 else "ğŸ¥‡ VERY GOOD" if result['auc'] >= 0.8 else "ğŸ¥ˆ GOOD" if result['auc'] >= 0.7 else "ğŸ¥‰ FAIR"
            print(f"    âœ… {grade} (AUC: {result['auc']:.4f})")
    
    # ç·åˆã‚µãƒãƒªãƒ¼ä½œæˆ
    if results:
        print(f"\nğŸ“Š Creating comprehensive summary...")
        visualizer.create_summary_report(results, "comprehensive_summary")
    
    total_time = time.time() - total_start
    
    # æœ€çµ‚ã‚µãƒãƒªãƒ¼
    print(f"\n{'ğŸ¨' * 60}")
    print("   VISUALIZATION DEMO COMPLETE")
    print("ğŸ¨" * 60)
    
    if results:
        avg_auc = np.mean([r['auc'] for r in results.values()])
        print(f"ğŸ“Š Average AUC: {avg_auc:.4f}")
        print(f"â±ï¸  Total time: {total_time:.1f} seconds")
        print(f"ğŸ“ Visualizations saved in: anomaly_visualizations/")
        
        # æœ€è‰¯çµæœã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        best_category = max(results.keys(), key=lambda k: results[k]['auc'])
        best_auc = results[best_category]['auc']
        print(f"ğŸ† Best performance: {best_category} (AUC: {best_auc:.4f})")
    
    print("ğŸ¨" * 60)


if __name__ == "__main__":
    print("ğŸ¨ Starting AnomalyVFM Advanced Visualization Demo...")
    run_visualization_demo()
    print("\nâœ… Visualization Demo Complete! ğŸ‰")