# demo_ad2_anomalyvfm_gpu.py - GPUæœ€é©åŒ–ç‰ˆ
import torch
import timm
import numpy as np
from torch.utils.data import DataLoader
from sklearn.covariance import EmpiricalCovariance
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import StandardScaler
import warnings
import time

from dataset_ad2 import AD2TrainDataset, AD2TestDataset

# è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings('ignore')

# GPUæœ€é©åŒ–è¨­å®š
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    # GPUè¨­å®šæœ€é©åŒ–
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False


def extract_embeddings(model, loader, desc=""):
    """
    GPUæœ€é©åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡æŠ½å‡º
    """
    model.eval()
    embeddings = []
    
    with torch.no_grad():
        for batch_idx, x in enumerate(loader):
            if isinstance(x, (tuple, list)):
                x = x[0]
            x = x.to(device, non_blocking=True)
            
            # ç‰¹å¾´é‡æŠ½å‡º
            features = model(x)
            embeddings.append(features.cpu())
            
            if batch_idx % 10 == 0 and desc:
                print(f"  {desc} batch {batch_idx}/{len(loader)}")
                
    # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ã«çµåˆ
    embeddings = torch.cat(embeddings, dim=0).numpy()
    print(f"  Extracted embeddings shape: {embeddings.shape}")
    return embeddings


def compute_gaussian_params(embeddings):
    """
    æ­£è¦åŒ–ã•ã‚ŒãŸã‚¬ã‚¦ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨ˆç®—
    """
    print(f"  Computing Gaussian parameters for {embeddings.shape[0]} samples...")
    
    # ç‰¹å¾´é‡æ­£è¦åŒ–
    scaler = StandardScaler()
    embeddings_scaled = scaler.fit_transform(embeddings)
    
    # ã‚¬ã‚¦ã‚¹åˆ†å¸ƒãƒ•ã‚£ãƒƒãƒˆ
    cov_estimator = EmpiricalCovariance(assume_centered=False)
    cov_estimator.fit(embeddings_scaled)
    
    return cov_estimator.location_, cov_estimator.precision_, scaler


def mahalanobis_distance_batch(features, mean, precision):
    """
    ãƒãƒƒãƒå‡¦ç†ã§ãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢ã‚’è¨ˆç®—
    """
    diff = features - mean
    distances = np.sum((diff @ precision) * diff, axis=1)
    return distances


def evaluate_category_gpu(root, category, batch_size=64):
    """
    GPUæœ€é©åŒ–ã•ã‚ŒãŸç•°å¸¸æ¤œçŸ¥è©•ä¾¡
    """
    print(f"\n{'='*60}")
    print(f"  GPU Anomaly Detection: {category}")
    print(f"{'='*60}")

    start_time = time.time()

    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        train_ds = AD2TrainDataset(root, category, image_size=224)
        test_ds = AD2TestDataset(root, category, image_size=224)

        if len(train_ds) == 0:
            print(f"  âŒ ERROR: No training images for {category}")
            return 0.0
        
        if len(test_ds) == 0:
            print(f"  âŒ ERROR: No test images for {category}")
            return 0.0

        # DataLoaderï¼ˆGPUæœ€é©åŒ–ï¼‰
        train_loader = DataLoader(
            train_ds, 
            batch_size=batch_size, 
            shuffle=False, 
            num_workers=2,  # Windowsã§ã¯2-4ãŒæ¨å¥¨
            pin_memory=True,
            persistent_workers=True
        )
        
        test_loader = DataLoader(
            test_ds, 
            batch_size=batch_size, 
            shuffle=False, 
            num_workers=2,
            pin_memory=True,
            persistent_workers=True
        )

        # è»½é‡ã§é«˜æ€§èƒ½ãªEfficientNet-B0ãƒ¢ãƒ‡ãƒ«
        print("  ğŸš€ Loading EfficientNet-B0 (GPU optimized)...")
        model = timm.create_model(
            "efficientnet_b0.ra_in1k", 
            pretrained=True, 
            num_classes=0,  # ç‰¹å¾´é‡æŠ½å‡ºå°‚ç”¨
        )
        model = model.to(device)
        model.eval()

        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡æŠ½å‡º
        print("  ğŸ“Š Extracting training features...")
        train_features = extract_embeddings(model, train_loader, "Train")
        
        # ã‚¬ã‚¦ã‚¹åˆ†å¸ƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®—
        mean, precision, scaler = compute_gaussian_params(train_features)

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
        print("  ğŸ” Evaluating anomaly detection...")
        all_scores = []
        all_labels = []

        with torch.no_grad():
            for batch_idx, (x, y) in enumerate(test_loader):
                x = x.to(device, non_blocking=True)
                
                # ç‰¹å¾´é‡æŠ½å‡º
                features = model(x)
                features_np = features.cpu().numpy()
                
                # æ­£è¦åŒ–
                features_scaled = scaler.transform(features_np)
                
                # ãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢è¨ˆç®—ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
                scores = mahalanobis_distance_batch(features_scaled, mean, precision)
                
                all_scores.extend(scores)
                all_labels.extend(y.numpy())
                
                if batch_idx % 5 == 0:
                    print(f"    Processing batch {batch_idx+1}/{len(test_loader)}")

        # AUCè¨ˆç®—
        auc_score = roc_auc_score(all_labels, all_scores)
        
        # çµ±è¨ˆæƒ…å ±
        normal_scores = [all_scores[i] for i in range(len(all_scores)) if all_labels[i] == 0]
        anomaly_scores = [all_scores[i] for i in range(len(all_scores)) if all_labels[i] == 1]
        
        elapsed_time = time.time() - start_time
        
        print(f"\n  ğŸ“ˆ Results for {category}:")
        print(f"    AUC Score: {auc_score:.4f}")
        print(f"    Normal samples: {len(normal_scores)} (scores: {min(normal_scores):.2f} - {max(normal_scores):.2f})")
        print(f"    Anomaly samples: {len(anomaly_scores)} (scores: {min(anomaly_scores):.2f} - {max(anomaly_scores):.2f})")
        print(f"    Evaluation time: {elapsed_time:.1f} seconds")
        
        return auc_score
        
    except Exception as e:
        print(f"  âŒ ERROR in {category}: {str(e)}")
        return 0.0
    
    finally:
        # GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
        if torch.cuda.is_available():
            torch.cuda.empty_cache()


if __name__ == "__main__":
    # ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹
    root = r"C:\Users\yasun\MultimodalAD\anomalyvfm_mvtec_ad2\data\MVTec AD2"
    
    # å˜ä¸€ã‚«ãƒ†ã‚´ãƒªãƒ†ã‚¹ãƒˆ
    category = "can"
    auc = evaluate_category_gpu(root, category)
    
    print(f"\nğŸ¯ Final Result: {category} AUC = {auc:.4f}")
    
    # GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¡¨ç¤º
    if torch.cuda.is_available():
        memory_used = torch.cuda.max_memory_allocated() / 1024**3
        print(f"ğŸ–¥ï¸  Max GPU Memory Used: {memory_used:.2f} GB")