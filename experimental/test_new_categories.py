# test_new_categories.py - æ–°è¦4ã‚«ãƒ†ã‚´ãƒªã®ãƒ†ã‚¹ãƒˆ
import torch
import timm
import numpy as np
from torch.utils.data import DataLoader
from sklearn.covariance import EmpiricalCovariance
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import StandardScaler
import warnings
import time
from datetime import datetime

from dataset_ad2 import AD2TrainDataset, AD2TestDataset

warnings.filterwarnings('ignore')

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ðŸš€ Testing New Categories - Using device: {device}")

if torch.cuda.is_available():
    print(f"ðŸ–¥ï¸  GPU: {torch.cuda.get_device_name(0)}")


def quick_evaluate_category(root, category, batch_size=64):
    """
    æ–°ã‚«ãƒ†ã‚´ãƒªã®ç°¡æ˜“è©•ä¾¡
    """
    print(f"\n{'='*50}")
    print(f"  ðŸŽ¯ Testing: {category.upper()}")
    print(f"{'='*50}")
    
    start_time = time.time()
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¢ºèª
        train_ds = AD2TrainDataset(root, category, image_size=224)
        test_ds = AD2TestDataset(root, category, image_size=224)
        
        print(f"  ðŸ“Š Found: {len(train_ds)} train, {len(test_ds)} test images")
        
        if len(train_ds) == 0 or len(test_ds) == 0:
            print("  âŒ No data available")
            return 0.0
        
        # DataLoaderï¼ˆé«˜é€ŸåŒ–ã®ãŸã‚å¤§ãã‚ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼‰
        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, 
                                 num_workers=2, pin_memory=True if device=='cuda' else False)
        test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, 
                                num_workers=2, pin_memory=True if device=='cuda' else False)
        
        # è»½é‡ãƒ¢ãƒ‡ãƒ«ã§é«˜é€Ÿãƒ†ã‚¹ãƒˆ
        print("  ðŸ¤– Loading EfficientNet-B0...")
        model = timm.create_model("efficientnet_b0.ra_in1k", pretrained=True, num_classes=0)
        model = model.to(device).eval()
        
        # è¨“ç·´ç‰¹å¾´é‡æŠ½å‡º
        train_features = []
        with torch.no_grad():
            for batch_idx, images in enumerate(train_loader):
                images = images.to(device, non_blocking=True)
                feats = model(images)
                train_features.append(feats.cpu())
                
                if batch_idx % 5 == 0:
                    print(f"    Train batch {batch_idx+1}/{len(train_loader)}")
        
        train_features = torch.cat(train_features, dim=0).numpy()
        
        # ãƒ†ã‚¹ãƒˆç‰¹å¾´é‡æŠ½å‡º
        test_features = []
        test_labels = []
        
        with torch.no_grad():
            for batch_idx, (images, labels) in enumerate(test_loader):
                images = images.to(device, non_blocking=True)
                feats = model(images)
                test_features.append(feats.cpu())
                test_labels.extend(labels.numpy())
                
                if batch_idx % 3 == 0:
                    print(f"    Test batch {batch_idx+1}/{len(test_loader)}")
        
        test_features = torch.cat(test_features, dim=0).numpy()
        test_labels = np.array(test_labels)
        
        # ç°¡æ˜“ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—
        scaler = StandardScaler()
        train_scaled = scaler.fit_transform(train_features)
        test_scaled = scaler.transform(test_features)
        
        # L2è·é›¢ãƒ™ãƒ¼ã‚¹
        mean_train = np.mean(train_scaled, axis=0)
        scores = np.linalg.norm(test_scaled - mean_train, axis=1)
        
        # AUCè¨ˆç®—
        auc = roc_auc_score(test_labels, scores)
        
        elapsed_time = time.time() - start_time
        
        # çµæžœè¡¨ç¤º
        normal_count = np.sum(test_labels == 0)
        anomaly_count = np.sum(test_labels == 1)
        
        grade = "ðŸ† EXCELLENT" if auc >= 0.90 else "ðŸ¥‡ VERY GOOD" if auc >= 0.80 else "ðŸ¥ˆ GOOD" if auc >= 0.70 else "ðŸ¥‰ FAIR" if auc >= 0.60 else "ðŸ“ˆ POOR"
        
        print(f"\n  ðŸ“Š Quick Results:")
        print(f"    AUC Score: {auc:.4f}")
        print(f"    Grade: {grade}")
        print(f"    Samples: {normal_count} normal, {anomaly_count} anomaly")
        print(f"    Time: {elapsed_time:.1f}s")
        
        return auc
        
    except Exception as e:
        print(f"  âŒ Error: {str(e)}")
        return 0.0
    
    finally:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()


def test_new_4_categories():
    """
    æ–°è¦4ã‚«ãƒ†ã‚´ãƒªã®ç°¡æ˜“ãƒ†ã‚¹ãƒˆ
    """
    root = r"C:\Users\yasun\MultimodalAD\anomalyvfm_mvtec_ad2\data\MVTec AD2"
    new_categories = ["sheet_metal", "vial", "wallplugs", "walnuts"]
    
    print("ðŸ”¥" * 50)
    print("   Testing New 4 Categories")
    print("ðŸ”¥" * 50)
    print(f"â° Start: {datetime.now().strftime('%H:%M:%S')}")
    
    results = []
    total_start = time.time()
    
    for i, category in enumerate(new_categories, 1):
        print(f"\nðŸŽ¯ [{i}/4] Testing: {category}")
        auc = quick_evaluate_category(root, category)
        results.append((category, auc))
    
    # ã‚µãƒžãƒªãƒ¼
    total_time = time.time() - total_start
    
    print(f"\n{'='*50}")
    print("   NEW CATEGORIES SUMMARY")
    print("="*50)
    
    total_auc = 0
    valid_count = 0
    
    for category, auc in results:
        grade = "ðŸ†" if auc >= 0.90 else "ðŸ¥‡" if auc >= 0.80 else "ðŸ¥ˆ" if auc >= 0.70 else "ðŸ¥‰" if auc >= 0.60 else "ðŸ“ˆ"
        print(f"{category:<12}: {auc:.4f} {grade}")
        
        if auc > 0.0:
            total_auc += auc
            valid_count += 1
    
    if valid_count > 0:
        avg_auc = total_auc / valid_count
        print(f"{'AVERAGE':<12}: {avg_auc:.4f} ðŸŒŸ")
    
    print(f"\nâ±ï¸  Total time: {total_time:.1f}s")
    print(f"âš¡ Average: {total_time/len(new_categories):.1f}s per category")
    
    if torch.cuda.is_available():
        memory_used = torch.cuda.max_memory_allocated() / 1024**3
        print(f"ðŸ–¥ï¸  GPU Memory: {memory_used:.2f} GB")
    
    return results


if __name__ == "__main__":
    print("ðŸš€ Testing new 4 categories...")
    results = test_new_4_categories()
    print("\nâœ… New category testing complete! ðŸŽ‰")