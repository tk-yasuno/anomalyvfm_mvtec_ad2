# final_anomalyvfm_demo.py - æœ€çµ‚ãƒ‡ãƒ¢ç‰ˆ
import torch
import timm
import numpy as np
from torch.utils.data import DataLoader
from sklearn.covariance import EmpiricalCovariance
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import StandardScaler
import warnings
import time
from datetime import datetime

from dataset_ad2 import AD2TrainDataset, AD2TestDataset

warnings.filterwarnings('ignore')

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸš€ AnomalyVFM Final Demo - Using device: {device}")

if torch.cuda.is_available():
    print(f"ğŸ–¥ï¸  GPU: {torch.cuda.get_device_name(0)}")
    print(f"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    torch.backends.cudnn.benchmark = True


def extract_features_efficient(model, loader, desc=""):
    """
    åŠ¹ç‡çš„ãªç‰¹å¾´é‡æŠ½å‡º
    """
    model.eval()
    features = []
    
    with torch.no_grad():
        for batch_idx, data in enumerate(loader):
            if isinstance(data, tuple):
                images = data[0]
            else:
                images = data
                
            images = images.to(device, non_blocking=True)
            
            # ç‰¹å¾´é‡æŠ½å‡º
            feats = model(images)
            features.append(feats.cpu())
            
            if batch_idx % 5 == 0 and desc:
                print(f"    {desc} batch {batch_idx+1}/{len(loader)}")
    
    return torch.cat(features, dim=0).numpy()


def compute_anomaly_scores_robust(train_features, test_features):
    """
    ãƒ­ãƒã‚¹ãƒˆãªç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—
    """
    # æ¨™æº–åŒ–
    scaler = StandardScaler()
    train_scaled = scaler.fit_transform(train_features)
    test_scaled = scaler.transform(test_features)
    
    # ãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢ãƒ™ãƒ¼ã‚¹ã®ã‚¹ã‚³ã‚¢
    try:
        cov = EmpiricalCovariance().fit(train_scaled)
        mean = cov.location_
        precision = cov.precision_
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚³ã‚¢è¨ˆç®—
        scores = []
        for sample in test_scaled:
            diff = sample - mean
            score = float(diff @ precision @ diff.T)
            scores.append(score)
        
        return np.array(scores)
        
    except Exception as e:
        print(f"    Warning: Mahalanobis failed ({str(e)}), using L2 distance")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚·ãƒ³ãƒ—ãƒ«ãªL2è·é›¢
        mean_train = np.mean(train_scaled, axis=0)
        scores = np.linalg.norm(test_scaled - mean_train, axis=1)
        return scores


def evaluate_category_final(root, category, batch_size=32):
    """
    æœ€çµ‚ç‰ˆã‚«ãƒ†ã‚´ãƒªè©•ä¾¡
    """
    print(f"\n{'='*60}")
    print(f"  ğŸ¯ AnomalyVFM Demo: {category.upper()}")
    print(f"{'='*60}")
    
    start_time = time.time()
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ (DINOv2ç”¨: 518x518)
        train_ds = AD2TrainDataset(root, category, image_size=518)
        test_ds = AD2TestDataset(root, category, image_size=518)
        
        print(f"  ğŸ“Š Data: {len(train_ds)} train, {len(test_ds)} test")
        
        if len(train_ds) == 0 or len(test_ds) == 0:
            print("  âŒ No data available")
            return 0.0
        
        # DataLoader
        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, 
                                 num_workers=2, pin_memory=True if device=='cuda' else False)
        test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, 
                                num_workers=2, pin_memory=True if device=='cuda' else False)
        
        # ãƒ¢ãƒ‡ãƒ«: DINOv2-ViT-Baseï¼ˆæœ€æ–°ã®è‡ªå·±æ•™å¸«å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼‰
        print("  ğŸ¤– Loading DINOv2-ViT-Base...")
        model = timm.create_model("vit_base_patch14_dinov2", pretrained=True, num_classes=0)
        model = model.to(device).eval()
        
        # è¨“ç·´ç‰¹å¾´é‡
        print("  ğŸ“ˆ Extracting training features...")
        train_features = extract_features_efficient(model, train_loader, "Train")
        print(f"    Shape: {train_features.shape}")
        
        # ãƒ†ã‚¹ãƒˆç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«
        print("  ğŸ” Extracting test features...")
        test_features = []
        test_labels = []
        
        with torch.no_grad():
            for batch_idx, (images, labels) in enumerate(test_loader):
                images = images.to(device, non_blocking=True)
                feats = model(images)
                test_features.append(feats.cpu())
                test_labels.extend(labels.numpy())
                
                if batch_idx % 3 == 0:
                    print(f"    Test batch {batch_idx+1}/{len(test_loader)}")
        
        test_features = torch.cat(test_features, dim=0).numpy()
        test_labels = np.array(test_labels)
        
        # ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—
        print("  âš¡ Computing anomaly scores...")
        scores = compute_anomaly_scores_robust(train_features, test_features)
        
        # AUCè¨ˆç®—
        auc = roc_auc_score(test_labels, scores)
        
        # çµ±è¨ˆæƒ…å ±
        normal_count = np.sum(test_labels == 0)
        anomaly_count = np.sum(test_labels == 1)
        
        elapsed_time = time.time() - start_time
        
        print(f"\n  ğŸ“Š Results:")
        print(f"    AUC Score: {auc:.4f}")
        print(f"    Normal samples: {normal_count}")
        print(f"    Anomaly samples: {anomaly_count}")
        print(f"    Processing time: {elapsed_time:.1f}s")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
        if auc >= 0.90:
            grade = "ğŸ† EXCELLENT"
        elif auc >= 0.80:
            grade = "ğŸ¥‡ VERY GOOD"
        elif auc >= 0.70:
            grade = "ğŸ¥ˆ GOOD"
        elif auc >= 0.60:
            grade = "ğŸ¥‰ FAIR"
        else:
            grade = "ğŸ“ˆ NEEDS IMPROVEMENT"
            
        print(f"    Performance: {grade}")
        
        return auc
        
    except Exception as e:
        print(f"  âŒ Error: {str(e)}")
        return 0.0
    
    finally:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()


def run_multi_category_demo():
    """
    å…¨7ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¢å®Ÿè¡Œ
    """
    root = r"C:\Users\yasun\MultimodalAD\anomalyvfm_mvtec_ad2\data\MVTec AD2"
    categories = [
        "can", "fabric", "fruit_jelly",  # æ—¢å­˜ã®3ã‚«ãƒ†ã‚´ãƒª
        "sheet_metal", "vial", "wallplugs", "walnuts"  # è¿½åŠ ã®4ã‚«ãƒ†ã‚´ãƒª
    ]
    
    print("ğŸ”¥" * 70)
    print("   AnomalyVFM MVP - Full 7-Category Anomaly Detection Demo")
    print("ğŸ”¥" * 70)
    print(f"â° Start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“‚ Categories: {categories}")
    print(f"ğŸ¯ Total categories: {len(categories)}")
    
    results = []
    total_start = time.time()
    
    for i, category in enumerate(categories, 1):
        print(f"\nğŸ¯ [{i}/{len(categories)}] Processing: {category}")
        auc = evaluate_category_final(root, category)
        results.append((category, auc))
    
    # çµæœã‚µãƒãƒªãƒ¼
    total_time = time.time() - total_start
    
    print("\n" + "ğŸ" * 70)
    print("   FINAL RESULTS SUMMARY - ALL 7 CATEGORIES")
    print("ğŸ" * 70)
    
    print(f"{'Category':<15} {'AUC':<10} {'Grade'}")
    print("-" * 40)
    
    total_auc = 0
    valid_count = 0
    excellent_count = 0
    good_count = 0
    
    for category, auc in results:
        if auc >= 0.90:
            grade = "ğŸ† EXCELLENT"
        elif auc >= 0.80:
            grade = "ğŸ¥‡ VERY GOOD"
        elif auc >= 0.70:
            grade = "ğŸ¥ˆ GOOD"
        elif auc >= 0.60:
            grade = "ğŸ¥‰ FAIR"
        elif auc > 0.0:
            grade = "ğŸ“ˆ POOR"
        else:
            grade = "âŒ FAILED"
            
        print(f"{category:<15} {auc:.4f}     {grade}")
        
        if auc > 0.0:
            total_auc += auc
            valid_count += 1
    
    if valid_count > 0:
        avg_auc = total_auc / valid_count
        print("-" * 40)
        print(f"{'AVERAGE':<15} {avg_auc:.4f}     {'ğŸŒŸ Overall Score'}")
        
        # çµ±è¨ˆæƒ…å ±
        print(f"\nğŸ“ˆ Performance Statistics:")
        print(f"  ğŸ† Excellent (â‰¥0.90): {excellent_count}/{len(categories)}")
        print(f"  ğŸ¥‡ Good+ (â‰¥0.70): {good_count + excellent_count}/{len(categories)}")
        print(f"  âœ… Valid results: {valid_count}/{len(categories)}")
    
    print(f"\nâ±ï¸  Total time: {total_time:.1f} seconds")
    print(f"âš¡ Average time per category: {total_time/len(categories):.1f} seconds")
    print(f"ğŸ End: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    if torch.cuda.is_available():
        memory_used = torch.cuda.max_memory_allocated() / 1024**3
        print(f"ğŸ–¥ï¸  Peak GPU Memory: {memory_used:.2f} GB")
    
    print("ğŸ”¥" * 70)
    
    # çµæœä¿å­˜
    with open("demo_results.txt", "w", encoding="utf-8") as f:
        f.write("AnomalyVFM MVP Demo Results\n")
        f.write("=" * 30 + "\n")
        f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Device: {device.upper()}\n")
        f.write("-" * 30 + "\n")
        for category, auc in results:
            f.write(f"{category}: {auc:.4f}\n")
        if valid_count > 0:
            f.write(f"Average: {avg_auc:.4f}\n")
        f.write(f"Total time: {total_time:.1f}s\n")
    
    print("ğŸ“„ Results saved to: demo_results.txt")
    

if __name__ == "__main__":
    # 7ã‚«ãƒ†ã‚´ãƒªä¸€æ‹¬ãƒ‡ãƒ¢å®Ÿè¡Œ
    run_multi_category_demo()